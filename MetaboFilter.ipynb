{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Overview/ToDo:\n",
    "\n",
    "Import Pandas, Numpy, and StringIO libraries\n",
    "    Pandas      <-  data manipulation and analysis, provides data structures for efficiently storing and accessing data\n",
    "    Numpy       <-  numerical computations, provides support for large multi-dimensional arrays and matrices\n",
    "    StringIO    <-  read text data from memory\n",
    "\n",
    "Reads 2 CSV files and 2 Excel files using the pd.read_csv() and pd.read_excel() functions\n",
    "\n",
    "CSV files and Excel file are read into Pandas dataframes.\n",
    "\n",
    "Use sheet_name parameter to specify the sheet name in the Excel file to be read\n",
    "\n",
    "Renames the columns of the CSV dataframes using the rename() function\n",
    "Map the negative and positive ion intensities by iterating over the rows of the dataframes\n",
    "Check the conditions using the iterrows() function\n",
    "Use the at() function to update the values of the df_pos dataframe\n",
    "\n",
    "Removes undefined InChiKey values from the df_pos dataframe and reorder the rows\n",
    "Use the astype() function and the < operator for re-ordering by InChiKey and MSI_level\n",
    "Reorder the rows by InChiKey, MSI_level, and QC_RSD using the sort_values() function\n",
    "\n",
    "Read in another Excel file into a Pandas dataframe and select a subset of columns using the [] operator\n",
    "\n",
    "Reads another Excel file and select columns to keep from the reference library dataframe\n",
    "Sort the reference library dataframe by InChiKey\n",
    "Remove leading and trailing whitespaces from the InChiKey column of both dataframes\n",
    "Remove duplicates from the reference library dataframe based on InChiKey using the drop_duplicates() function\n",
    "Merges the reference library dataframe with the unknown dataframe based on InChiKey using the merge() function\n",
    "\n",
    "Select columns to keep from the reference library dataframe and converts the Metabolite.name column to uppercase\n",
    "Remove leading and trailing whitespaces\n",
    "Remove duplicates from the reference library dataframe based on Metabolite.name using the drop_duplicates() function\n",
    "Merge the reference library dataframe with the unknown dataframe based on Metabolite.name using the merge() function\n",
    "\n",
    "Remove the QC_RSD column from the final dataframe\n",
    "Concatenate the final dataframe with the unknown dataframe through the concat() function\n",
    "Sort the final dataframe by MSI_level and InChiKey using the sort_values() function\n",
    "Replace the MSI_level values of 2, 3, and 4 with 2A, 2B, and 2C respectively using the replace() function\n",
    "Select the final columns to keep using the [] operator and write the final dataframe to an Excel file using the to_excel() function\n",
    "\n",
    "Break down pipeline steps               ✓\n",
    "Convert R code into Python Notebook     ✔\n",
    "Successfully run locally                ✗\n",
    "Run on VM                               ✘\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#   Attempt 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "# Read CSV and Excel files\n",
    "df_neg = pd.read_excel('C:/MetaboFilter-PythonFilter/Jon_Reverse_neg_052323-Example.xlsx', sheet_name='Know_compound_RT_match')\n",
    "df_pos = pd.read_excel('C:/MetaboFilter-PythonFilter/Jon_Reverse_pos_052323-Example.xlsx', sheet_name='Know_compound_RT_match')\n",
    "df1 = pd.read_csv('C:/MetaboFilter-PythonFilter/Hilic_IROA_IS_negative_lib.csv')\n",
    "df2 = pd.read_csv('C:/MetaboFilter-PythonFilter/Reverse_IROA_IS_positive_lib.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "df_neg = df_neg.rename(columns={'InChiKey': 'InChiKey', 'RT_inlib': 'RT_inlib', 'Average_Mz': 'Average_Mz', 'Average_Rt_min': 'Average_Rt_min', 'Metabolite.name': 'Metabolite_name'})\n",
    "df1 = df1.rename(columns={'Metabolite_name': 'Metabolite_name', 'Average_Mz': 'Average_Mz', 'Average_Rt_min': 'Average_Rt_min', 'InChiKey': 'InChiKey'})\n",
    "df_pos = df_pos.rename(columns={'InChiKey': 'InChiKey', 'RT_inlib': 'RT_inlib', 'Average_Mz': 'Average_Mz', 'Average_Rt_min': 'Average_Rt_min', 'Metabolite.name': 'Metabolite_name'})\n",
    "df2 = df2.rename(columns={'Metabolite_name': 'Metabolite_name', 'Average_Mz': 'Average_Mz', 'Average_Rt_min': 'Average_Rt_min', 'InChiKey': 'InChiKey'})\n",
    "\n",
    "# Mapping negative and positive ion intensities\n",
    "for i, row in df_neg.iterrows():\n",
    "    for j, row2 in df_pos.iterrows():\n",
    "        if (row['InChiKey'] == row2['InChiKey']) and (np.abs(row['Average_Mz'] - row2['Average_Mz']) <= 0.005) and (np.abs(row['Average_Mz'] - row2['Average_Mz']) <= 0.005) and (np.abs(row['Average_Rt_min'] - row2['Average_Rt_min']) <= 0.3) and (np.abs(row['Average_Rt_min'] - row2['Average_Rt_min']) <= 0.3):\n",
    "            df_pos.at[i, 'MSI_level'] = \"1\"\n",
    "            df_pos.at[i, 'RT_inlib'] = df2['Average_Rt_min']\n",
    "\n",
    "# Mapping MSI levels\n",
    "for i in range(len(df_pos)):\n",
    "    if df_pos.at[i, 'Total.score'] >= 95:\n",
    "        df_pos.at[i, 'MSI_level'] = \"2\"\n",
    "\n",
    "# Remove undefined InChiKey values\n",
    "df_undefine = df_pos[~df_pos['InChiKey'].str.contains('undefined')]\n",
    "\n",
    "# Reorder rows by InChiKey and MSI_level\n",
    "df_undefine = df_undefine[df_undefine['InChiKey'].astype(str) < df_undefine['InChiKey'].astype(str)]\n",
    "\n",
    "# Reorder rows by InChiKey, MSI_level, and QC_RSD\n",
    "df_all = df_all[order(df_all['InChiKey'], df_all['MSI_level'], df_all['QC_RSD'])]\n",
    "\n",
    "# read the dataset into a pandas dataframe\n",
    "df_undefine = pd.read_excel('C:/MetaboFilter-PythonFilter/Tricore_Reaction_Reverse_neg_processed_R.xlsx', sheet_name='Unknown_compound')\n",
    "\n",
    "# define the columns to keep\n",
    "cols = [\"Metabolite.name\", \"Average.Rt.min.\", \"Average.Mz\", \"Adduct.type\", \"MSI_level\", \"InChiKey\", \"QC_RSD\", sample_col]\n",
    "\n",
    "# subset the dataframe using only the selected columns\n",
    "df_undefine = df_undefine[cols]\n",
    "\n",
    "# read the reference library into a pandas dataframe\n",
    "lb = pd.read_excel('C:/MetaboFilter-PythonFilter/Chemical Identification.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# select the columns to keep from the reference library dataframe\n",
    "lb_cols = [\"InChiKey\", \"SMILES\", \"PubChem.CID\", \"KEGG.ID\"]\n",
    "lb_1 = lb[lb_cols]\n",
    "\n",
    "# sort the reference library dataframe by InChiKey\n",
    "lb_1 = lb_1.sort_values(by='InChiKey')\n",
    "\n",
    "# remove leading and trailing whitespaces from the InChiKey column of both dataframes\n",
    "lb_1['InChiKey'] = lb_1['InChiKey'].str.strip()\n",
    "df_undefine['InChiKey'] = df_undefine['InChiKey'].str.strip()\n",
    "\n",
    "# remove duplicates from the reference library dataframe based on InChiKey\n",
    "lb_1 = lb_1.drop_duplicates(subset='InChiKey')\n",
    "\n",
    "# merge the reference library dataframe with the unknown dataframe based on InChiKey\n",
    "df_final = pd.merge(df_undefine, lb_1, on='InChiKey', how='left')\n",
    "\n",
    "# select the columns to keep from the reference library dataframe\n",
    "lb_cols = [\"Metabolite.name\", \"SMILES\", \"PubChem.CID\", \"KEGG.ID\"]\n",
    "lb_2 = lb[lb_cols]\n",
    "\n",
    "# convert the Metabolite.name column to uppercase and remove leading and trailing whitespaces\n",
    "lb_2['Metabolite.name'] = lb_2['Metabolite.name'].str.upper()\n",
    "lb_2['Metabolite.name'] = lb_2['Metabolite.name'].str.strip()\n",
    "df_undefine['Metabolite.name'] = df_undefine['Metabolite.name'].str.strip()\n",
    "\n",
    "# remove duplicates from the reference library dataframe based on Metabolite.name\n",
    "lb_2 = lb_2.drop_duplicates(subset='Metabolite.name')\n",
    "\n",
    "# merge the reference library dataframe with the unknown dataframe based on Metabolite.name\n",
    "df_undefine = pd.merge(df_undefine, lb_2, on='Metabolite.name', how='left')\n",
    "\n",
    "# remove the QC_RSD column from the final dataframe\n",
    "df_final = df_final.drop(columns=['QC_RSD'])\n",
    "\n",
    "# concatenate the final dataframe with the unknown dataframe\n",
    "df_final = pd.concat([df_final, df_undefine], ignore_index=True)\n",
    "\n",
    "# sort the final dataframe by MSI_level and InChiKey\n",
    "df_final = df_final.sort_values(by=['MSI_level', 'InChiKey'])\n",
    "\n",
    "# replace the MSI_level values of 2, 3, and 4 with 2A, 2B, and 2C respectively\n",
    "df_final['MSI_level'].replace({'2': '2A', '3': '2B', '4': '2C'}, inplace=True)\n",
    "\n",
    "# select the final columns to keep\n",
    "col_format = [\"Metabolite.name\", \"Average.Rt.min.\", \"Average.Mz\", \"Adduct.type\", \"MSI_level\", \"InChiKey\", \"SMILES\", \"PubChem.CID\", \"KEGG.ID\", sample_col]\n",
    "df_final = df_final[col_format]\n",
    "\n",
    "# write the final dataframe to an excel file\n",
    "writer = pd.ExcelWriter('C:/MetaboFilter-PythonFilter/Jon_Reverse_Reaction_combine_data_process.xlsx', engine='openpyxl')\n",
    "df_final.to_excel(writer, sheet_name='final', index=False)\n",
    "df_undefine.to_excel(writer, sheet_name='unknown', index=False)\n",
    "writer.save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#   Attempt 2\n",
    "\n",
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "#from openpyxl import load_workbook\n",
    "#from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "# Read data from Excel files\n",
    "df_neg = pd.read_excel('C:/Users/Metabolomics-Shortcut.lnk/MetaboFilter-PythonFilter/Jon_Reverse_neg_052323-Example.xlsx', sheet_name='Know_compound_RT_match')\n",
    "df_pos = pd.read_excel('C:/Users/Metabolomics-Shortcut.lnk/MetaboFilter-PythonFilter/Jon_Reverse_pos_052323-Example.xlsx', sheet_name='Know_compound_RT_match')\n",
    "\n",
    "# Read data from CSV file and assign column names\n",
    "df1 = pd.read_csv('C:/Users/Metabolomics-Shortcut.lnk/MetaboFilter-PythonFilter/Hilic_IROA_IS_negative_lib.csv')\n",
    "df1.columns = ['Metabolite_name', 'Average_Mz', 'Average_Rt_min', 'InChiKey']\n",
    "\n",
    "# Update column names in df_neg\n",
    "df_neg.rename(columns={'Average.Rt.min.': 'Average_Rt_min', 'Average.Mz': 'Average_Mz', 'Metabolite.name': 'Metabolite_name'}, inplace=True)\n",
    "\n",
    "# Convert column values to appropriate data types\n",
    "#df1['Average_Rt_min'] = pd.to_numeric(df1['Average_Rt_min'])\n",
    "#df1.dtypes\n",
    "df1['Average_Rt_min'] = pd.to_numeric(df1['Average_Rt_min'])\n",
    "\n",
    "# Perform data transformations and matching\n",
    "df_neg['Metabolite_name'] = df_neg['Metabolite_name'].str.replace(\".\", \"\")\n",
    "df1['Metabolite_name'] = df1['Metabolite_name'].str.replace(\".\", \"\")\n",
    "df_neg['Metabolite_name'] = df_neg['Metabolite_name'].str.upper()\n",
    "df1['Metabolite_name'] = df1['Metabolite_name'].str.upper()\n",
    "df_neg['Metabolite_name'] = df_neg['Metabolite_name'].str.strip()\n",
    "df1['Metabolite_name'] = df1['Metabolite_name'].str.strip()\n",
    "\n",
    "# Perform matching based on specific conditions\n",
    "for i in range(len(df_neg)):\n",
    "    for j in range(len(df1)):\n",
    "        if (df_neg.loc[i, 'InChiKey'] == df1.loc[j, 'InChiKey'] and\n",
    "                df_neg.loc[i, 'Average_Mz'] >= df1.loc[j, 'Average_Mz'] - 0.005 and\n",
    "                df_neg.loc[i, 'Average_Mz'] <= df1.loc[j, 'Average_Mz'] + 0.005 and\n",
    "                df_neg.loc[i, 'Average_Rt_min'] >= df1.loc[j, 'Average_Rt_min'] - 0.3 and\n",
    "                df_neg.loc[i, 'Average_Rt_min'] <= df1.loc[j, 'Average_Rt_min'] + 0.3):\n",
    "            \n",
    "            df_neg.loc[i, 'MSI_level'] = \"1\"\n",
    "            df_neg.loc[i, 'RT_inlib'] = df1.loc[j, 'Average_Rt_min']\n",
    "\n",
    "# Update column names in df_neg\n",
    "df_neg.rename(columns={'Average_Rt_min': 'Average.Rt.min.', 'Average_Mz': 'Average.Mz', 'Metabolite_name': 'Metabolite.name'}, inplace=True)\n",
    "\n",
    "# Read data from CSV file into df2 and assign column names\n",
    "df2 = pd.read_csv('C:/Users/Metabolomics-Shortcut.lnk/MetaboFilter-PythonFilter/Hilic_IROA_IS_positive_lib.csv')\n",
    "df2.columns = ['Metabolite_name', 'Average_Mz', 'Average_Rt_min', 'InChiKey']\n",
    "#df2.columns\n",
    "\n",
    "# Set MSI_level and RT_inlib columns in df_pos\n",
    "df_pos = df_pos.assign(MSI_level=\"\", RT_inlib=\"\")\n",
    "df_pos = df_pos.reindex(columns=['MSI_level', 'RT_inlib'] + df_pos.columns[:-2].tolist())\n",
    "\n",
    "# Update column names in df_pos\n",
    "df_pos.rename(columns={\"Average.Rt.min.\": \"Average_Rt_min\", \"Average_Mz\": \"Average_Mz\", \"Metabolite.name\": \"Metabolite_name\"}, inplace=True)\n",
    "print(df_pos.columns)\n",
    "\n",
    "# Convert column values in df2 to appropriate data types\n",
    "df2['Average_Rt_min'] = pd.to_numeric(df2['Average_Rt_min'])\n",
    "print(df2.dtypes)\n",
    "\n",
    "# Perform string transformations on Metabolite_name columns in df_pos and df2\n",
    "df_pos['Metabolite_name'] = df_pos['Metabolite_name'].str.replace(\"[.]\", \"\")\n",
    "df2['Metabolite_name'] = df2['Metabolite_name'].str.replace(\"[.]\", \"\")\n",
    "df_pos['Metabolite_name'] = df_pos['Metabolite_name'].str.upper()\n",
    "df2['Metabolite_name'] = df2['Metabolite_name'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df2['Metabolite_name'] = df2['Metabolite_name'].str.upper()\n",
    "df_pos['Metabolite_name'] = df_pos['Metabolite_name'].str.strip()\n",
    "df2['Metabolite_name'] = df2['Metabolite_name'].str.strip()\n",
    "\n",
    "# Perform matching between df_pos and df2 based on specific conditions\n",
    "for i in range(len(df_pos)):\n",
    "    for j in range(len(df2)):\n",
    "        if (df_pos.loc[i, 'InChiKey'] == df2.loc[j, 'InChiKey']) and /\n",
    "                (df_pos.loc[i, 'Average_Mz'] >= df2.loc[j, 'Average_Mz'] - 0.005) and /\n",
    "                (df_pos.loc[i, 'Average_Mz'] <= df2.loc[j, 'Average_Mz'] + 0.005) and /\n",
    "                (df_pos.loc[i, 'Average_Rt_min'] >= df2.loc[j, 'Average_Rt_min'] - 0.3) and /\n",
    "                (df_pos.loc[i, 'Average_Rt_min'] <= df2.loc[j, 'Average_Rt_min'] + 0.3):\n",
    "            df_pos.loc[i, 'MSI_level'] = \"1\"\n",
    "            df_pos.loc[i, 'RT_inlib'] = df2.loc[j, 'Average_Rt_min']\n",
    "\n",
    "# Update column names in df_pos\n",
    "df_pos.rename(columns={\"Average_Rt_min\": \"Average.Rt.min.\", \"Average_Mz\": \"Average_Mz\", \"Metabolite_name\": \"Metabolite.name\"}, inplace=True)\n",
    "df_pos.columns = df_neg.columns\n",
    "\n",
    "# Combine df_neg and df_pos into a single dataframe, df\n",
    "df = pd.concat([df_neg, df_pos])\n",
    "\n",
    "# Sort df by MSI_level in descending order\n",
    "df = df.sort_values(by='MSI_level', ascending=False)\n",
    "\n",
    "# Create MSI_1 dataframe containing rows with MSI_level = '1'\n",
    "MSI_1 = df[df['MSI_level'] == '1']\n",
    "\n",
    "# Create df_1 dataframe containing rows with MSI_level not equal to '1'\n",
    "df_1 = df[df['MSI_level'] != '1']\n",
    "\n",
    "# Convert Total.score column in df_1 to numeric\n",
    "df_1['Total.score'] = pd.to_numeric(df_1['Total.score'])\n",
    "\n",
    "# Update MSI_level values in df_1 based on Total.score condition\n",
    "df_1.loc[df_1['Total.score'] >= 95, 'MSI_level'] = '2'\n",
    "\n",
    "# Sort df_1 by MSI_level in descending order\n",
    "df_1 = df_1.sort_values(by='MSI_level', ascending=False)\n",
    "\n",
    "# Create MSI_2 dataframe containing rows with MSI_level = '2'\n",
    "MSI_2 = df_1[df_1['MSI_level'] == '2']\n",
    "\n",
    "# Create df_2 dataframe containing rows with MSI_level not equal to '2'\n",
    "df_2 = df_1[df_1['MSI_level'] != '2']\n",
    "\n",
    "# Update MSI_level values in df_2 based on Total.score condition\n",
    "df_2.loc[df_2['Total.score'] >= 90, 'MSI_level'] = '3'\n",
    "\n",
    "# Update MSI_level values in df_2 not equal to '3' to '4'\n",
    "df_2.loc[df_2['MSI_level'] != '3', 'MSI_level'] = '4'\n",
    "\n",
    "# Combine MSI_1, MSI_2, and df_2 into dt_all dataframe\n",
    "dt_all = pd.concat([MSI_1, MSI_2, df_2])\n",
    "\n",
    "# Remove trailing spaces in InChiKey column\n",
    "dt_all['InChiKey'] = dt_all['InChiKey'].str.strip()\n",
    "\n",
    "# Separate dt_all into dt_undefine and dt_all based on InChiKey containing \"undefined\"\n",
    "dt_undefine = dt_all[~dt_all['InChiKey'].str.contains('undefined')]\n",
    "dt_all = dt_all[dt_all['InChiKey'].str.contains('undefined')]\n",
    "\n",
    "# Sort dt_all by InChiKey, MSI_level, and QC_RSD\n",
    "dt_all = dt_all.sort_values(by=['InChiKey', 'MSI_level', 'QC_RSD'])\n",
    "\n",
    "# Write dt_all to a CSV file named \"remove_rep.csv\"\n",
    "dt_all.to_csv('remove_rep.csv', index=False)\n",
    "\n",
    "# Remove duplicate rows based on InChiKey in dt_all and create final dataframe\n",
    "final = dt_all.drop_duplicates(subset='InChiKey')\n",
    "\n",
    "# Perform string transformations and sorting on dt_undefine\n",
    "dt_undefine['Metabolite.name'] = dt_undefine['Metabolite.name'].str.upper()\n",
    "dt_undefine['Metabolite.name'] = dt_undefine['Metabolite.name'].str.replace(\"[.]\", \"\")\n",
    "dt_undefine['Metabolite.name'] = dt_undefine['Metabolite.name'].str.strip()\n",
    "dt_undefine = dt_undefine.sort_values(by=['Metabolite.name', 'MSI_level', 'QC_RSD'])\n",
    "dt_undefine = dt_undefine.drop_duplicates(subset='Metabolite.name')\n",
    "\n",
    "# Define the column range for samples in dt_all\n",
    "start = dt_final.columns.get_loc(\"MS.MS.spectrum\") + 1\n",
    "end = dt_final.columns.get_loc('Avg') - 1\n",
    "sample_col = dt_final.columns[start:end]\n",
    "\n",
    "# Define the columns to select for dt_undefine and data\n",
    "cols = ['Metabolite.name', 'Average.Rt.min.', 'Average.Mz', 'Adduct.type', 'MSI_level', 'InChiKey', 'QC_RSD'] + list(sample_col)\n",
    "dt_undefine = dt_undefine[cols]\n",
    "data = final[cols]\n",
    "\n",
    "# Read \"Chemical Identification.xlsx\" file into lb dataframe\n",
    "lb = pd.read_excel('C:/Users/Metabolomics-Shortcut.lnk/MetaboFilter-PythonFilter/Chemical Identification.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Select specific columns from lb dataframe\n",
    "lb_1 = lb[['InChiKey', 'SMILES', 'PubChem.CID', 'KEGG.ID']]\n",
    "\n",
    "# Remove duplicate rows based on InChiKey in lb_1\n",
    "lb_1 = lb_1.sort_values(by='InChiKey')\n",
    "lb_1['InChiKey'] = lb_1['InChiKey'].str.strip()\n",
    "lb_1 = lb_1.drop_duplicates(subset='InChiKey')\n",
    "\n",
    "# Merge data and lb_1 dataframes based on InChiKey, keeping all rows from data\n",
    "dt_final = pd.merge(data, lb_1, on='InChiKey', how='left')\n",
    "\n",
    "# Remove QC_RSD column from dt_final\n",
    "dt_final = dt_final.drop(columns='QC_RSD')\n",
    "\n",
    "# Select specific columns from lb dataframe\n",
    "lb_2 = lb[['Metabolite.name', 'SMILES', 'PubChem.CID', 'KEGG.ID']]\n",
    "\n",
    "# Perform string transformations and sorting on lb_2 and dt_undefine\n",
    "lb_2['Metabolite.name'] = lb_2['Metabolite.name'].str.upper()\n",
    "lb_2['Metabolite.name'] = lb_2['Metabolite.name'].str.strip()\n",
    "dt_undefine['Metabolite.name'] = dt_undefine['Metabolite.name'].str.strip()\n",
    "lb_2 = lb_2.drop_duplicates(subset='Metabolite.name')\n",
    "\n",
    "# Merge dt_undefine and lb_2 dataframes based on Metabolite.name, keeping all rows from dt_undefine\n",
    "dt_undefine = pd.merge(dt_undefine, lb_2, on='Metabolite.name', how='left')\n",
    "\n",
    "# Remove QC_RSD column from dt_undefine\n",
    "dt_undefine = dt_undefine.drop(columns='QC_RSD')\n",
    "\n",
    "# Combine dt_final and dt_undefine into dt_final\n",
    "dt_final = pd.concat([dt_final, dt_undefine])\n",
    "\n",
    "# Display column names of dt_final\n",
    "print(dt_final.columns)\n",
    "\n",
    "# Sort dt_final by MSI_level\n",
    "dt_final = dt_final.sort_values(by='MSI_level')\n",
    "\n",
    "# Update MSI_level values in dt_final\n",
    "dt_final.loc[dt_final['MSI_level'] == '2', 'MSI_level'] = '2A'\n",
    "dt_final.loc[dt_final['MSI_level'] == '3', 'MSI_level'] = '2B'\n",
    "dt_final.loc[dt_final['MSI_level'] == '4', 'MSI_level'] = '2C'\n",
    "\n",
    "# Define the column format for dt_final\n",
    "col_format = ['Metabolite.name', 'Average.Rt.min.', 'Average.Mz', 'Adduct.type', 'MSI_level', 'InChiKey', 'SMILES', 'PubChem.CID', 'KEGG.ID'] + list(sample_col)\n",
    "dt_final = dt_final[col_format]\n",
    "\n",
    "# Sort dt_final by MSI_level and InChiKey\n",
    "dt_final = dt_final.sort_values(by=['MSI_level', 'InChiKey'])\n",
    "\n",
    "# Read \"Tricore_Reaction_Reverse_neg_processed_R.xlsx\" or similar file into unknown1 dataframe\n",
    "unknown1 = pd.read_excel('C:/Users/Metabolomics-Shortcut.lnk/MetaboFilter-PythonFilter/Jon_Reverse_neg_052323-Example.xlsx', sheet_name='Unknown_compound')\n",
    "\n",
    "# Read \"Tricore_Reaction_Reverse_pos_processed_R.xlsx\" or similar file into unknown2 dataframe\n",
    "unknown2 = pd.read_excel('C:/Users/Metabolomics-Shortcut.lnk/MetaboFilter-PythonFilter/Jon_Reverse_pos_052323-Example.xlsx', sheet_name='Unknown_compound')\n",
    "\n",
    "# Set column names of unknown2 to match unknown1\n",
    "unknown2.columns = unknown1.columns\n",
    "\n",
    "# Combine unknown1 and unknown2 into unknown dataframe\n",
    "unknown = pd.concat([unknown1, unknown2])\n",
    "\n",
    "# Select specific columns from unknown dataframe\n",
    "unknown = unknown[['Metabolite.name', 'Average.Rt.min.', 'Average.Mz', 'Adduct.type'] + list(sample_col)]\n",
    "\n",
    "# Set the value of \"Metabolite.name\" column in unknown dataframe to 'Unknown'\n",
    "unknown['Metabolite.name'] = 'Unknown'\n",
    "\n",
    "# Create a dictionary of datasets with names\n",
    "dataset_names = {'Known_compound': dt_final, 'Unknown_compound': unknown}\n",
    "\n",
    "# Write dataset_names to \"Ω_combine_data_process.xlsx\" file using openpyxl package\n",
    "'''\n",
    "#with pd.ExcelWriter('C:\\MetaboFilter-PythonFilter\\Jon_Reverse_Reaction_combine_data_process.xlsx', engine='openpyxl') as writer:\n",
    "#    for name, dataset in dataset_names.items():\n",
    "#        dataset.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "#    writer.save()\n",
    "'''\n",
    "# Write each dataset in dataset_names to a new sheet in the Excel file specified by filename.\n",
    "# Define the filename of the Excel file\n",
    "filename = 'C:/Users/Metabolomics-Shortcut.lnk/MetaboFilter-PythonFilter/Jon_Reverse_Reaction_combine_data_process.xlsx'\n",
    "\n",
    "# Create a Pandas Excel writer\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "\n",
    "# Iterate over each dataset in dataset_names\n",
    "for name, dataset in dataset_names.items():\n",
    "    # Write the dataset to a new sheet in the Excel file\n",
    "    dataset.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Attempt 3\n",
    "#   Python 3.9.1\n",
    "import sys\n",
    "import os\n",
    "sys.path\n",
    "print(1)\n",
    "# Load required libraries\n",
    "#pip install wheel\n",
    "#pip install pandas\n",
    "#py -m pip install pandas\n",
    "import pandas as pd\n",
    "import re\n",
    "print(2)\n",
    "#pip install selenium\n",
    "#pip3 uninstall selenium\n",
    "#pip3 install selenium\n",
    "import selenium\n",
    "#!{sys.executable} -m pip install openpyxl\n",
    "#!pip install openpyxl\n",
    "#!pip3 install openpyxl\n",
    "#python -m pip3 install openpyxl\n",
    "import openpyxl\n",
    "print(3)\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "print(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Tricore_Reaction_reverse_pos.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\varen\\Desktop\\SU23-FA23\\Metabolomics\\MetaboFilter-PythonFilter\\MetaboFilter.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/varen/Desktop/SU23-FA23/Metabolomics/MetaboFilter-PythonFilter/MetaboFilter.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpyxl\u001b[39;00m \u001b[39mimport\u001b[39;00m load_workbook\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/varen/Desktop/SU23-FA23/Metabolomics/MetaboFilter-PythonFilter/MetaboFilter.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Read CSV file\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/varen/Desktop/SU23-FA23/Metabolomics/MetaboFilter-PythonFilter/MetaboFilter.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mTricore_Reaction_reverse_pos.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/varen/Desktop/SU23-FA23/Metabolomics/MetaboFilter-PythonFilter/MetaboFilter.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Remove rows with missing values in the MS.MS.spectrum column\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/varen/Desktop/SU23-FA23/Metabolomics/MetaboFilter-PythonFilter/MetaboFilter.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m data \u001b[39m=\u001b[39m data[\u001b[39m~\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mMS.MS.spectrum\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misna()]\n",
      "File \u001b[1;32mc:\\Users\\varen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\varen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\varen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\varen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\varen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Tricore_Reaction_reverse_pos.csv'"
     ]
    }
   ],
   "source": [
    "# Read CSV file\n",
    "data = pd.read_csv('Reverse_IROA_IS_positive_lib.csv')\n",
    "\n",
    "# Remove rows with missing values in the MS.MS.spectrum column\n",
    "data = data[~data['MS.MS.spectrum'].isna()]\n",
    "\n",
    "# Extract columns containing Avg values\n",
    "cols = [col for col in data.columns if 'Avg' in col]\n",
    "\n",
    "# Remove rows containing \"w/o MS2\" or \"w/o MS2:\" in the Metabolite.name column\n",
    "data = data[~((data['Metabolite.name'].str.contains('w/o MS2')) | (data['Metabolite.name'].str.contains('w/o MS2:')))]\n",
    "\n",
    "# Separate ISTD, CUDA, and other metabolites\n",
    "ISTD = data[data['Metabolite.name'].str.contains('iSTD')]\n",
    "CUDA = data[data['Metabolite.name'].str.contains('CUDA')]\n",
    "ISTD = pd.concat([CUDA, ISTD])\n",
    "\n",
    "# Remove rows containing \"w/o MS2\" or \"w/o MS2:\" in the Metabolite.name column\n",
    "ISTD = ISTD[~((ISTD['Metabolite.name'].str.contains('w/o MS2')) | (ISTD['Metabolite.name'].str.contains('w/o MS2:')))]\n",
    "\n",
    "# Process data to calculate fold change and RSD\n",
    "data['RSD'] = data[cols].std(axis=1) / data[cols].mean(axis=1) * 100\n",
    "data['fold'] = data[cols].max(axis=1) / data[cols].mean(axis=1) * 100\n",
    "\n",
    "# Filter data based on fold change and QC_RSD\n",
    "sort_data = data[(data['fold'] >= 10) & (data['QC_RSD'] <= 30)].sort_values(by='QC_RSD', ascending=False)\n",
    "\n",
    "# Separate data into known and unknown compounds\n",
    "data_unknown = sort_data[sort_data['Metabolite.name'].str.contains('Unknown|w/o MS2', na=False)]\n",
    "data_known = sort_data[~sort_data['Metabolite.name'].str.contains('Unknown|w/o MS2', na=False)]\n",
    "data_known['MS.MS.spectrum'] = data_known['MS.MS.spectrum'].replace('None', '')\n",
    "\n",
    "# Merge with internal standard data\n",
    "ISTD = pd.concat([data_unknown, data_known])\n",
    "\n",
    "# Write processed data to an Excel file\n",
    "wb = load_workbook('Tricore_Reaction_Reverse_pos_processed_R.xlsx')\n",
    "ws = wb.create_sheet('Processed_data')\n",
    "with pd.ExcelWriter('Tricore_Reaction_Reverse_pos_processed_R.xlsx', engine='openpyxl') as writer:\n",
    "    writer.book = wb\n",
    "    writer.sheets = dict((ws.title, ws) for ws in wb.worksheets)\n",
    "    ISTD.to_excel(writer, sheet_name='Processed_data', index=False)\n",
    "    writer.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e295e83379f7e2de2e4dd91c775936957310ddc8acaa66b7098896f95c72790"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
